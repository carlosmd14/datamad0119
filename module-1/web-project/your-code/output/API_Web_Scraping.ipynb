{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relación entre el PIB de USA y el ingreso total por año del top 1000 de películas por votos de usuarios en IMDB.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se importan las librerías y métodos a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se define una clase para cada columna que se va a importar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clase para el título."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieSpider:\n",
    "   \n",
    "    def __init__(self, url_pattern, pages_to_scrape=25, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    def scrape_url(self, url):\n",
    "                \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"Timeout error\")\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print(\"Redirect error\")\n",
    "        except requests.exceptions.SSLError:\n",
    "            print(\"SSL error\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error\")\n",
    "        \n",
    "        if response.status_code >= 400 and response.status_code < 500:\n",
    "            print('Request failed because the resource either does not exist or is forbidden')\n",
    "        elif response.status_code >= 300:\n",
    "            print('Request failed because the response server encountered an error')\n",
    "        \n",
    "        return self.content_parser(response.content)\n",
    "        \n",
    "    def kickstart(self):\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for i in range(0, self.pages_to_scrape):\n",
    "            \n",
    "            if self.sleep_interval > 0:\n",
    "                    time.sleep(self.sleep_interval)\n",
    "            \n",
    "            output.append(self.scrape_url(self.url_pattern % i))\n",
    "            exit = self.scrape_url(self.url_pattern % i)\n",
    "            if exit == 0:\n",
    "                print(\"No more pages to scrape\")\n",
    "                break\n",
    "        \n",
    "        return output\n",
    "\n",
    "URL_PATTERN = 'https://www.imdb.com/search/title?groups=top_1000&sort=user_rating,desc&count=100&start=%s01&ref_=adv_nxt' \n",
    "\n",
    "def titles_parser(content):\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    text = [element.text for element in soup.find_all('a') if element.parent.name == 'h3']\n",
    "    \n",
    "    return text\n",
    "\n",
    "titles_spider = MovieSpider(URL_PATTERN, 10, content_parser=titles_parser)\n",
    "titles = [item for sublist in titles_spider.kickstart() for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cadena perpetua',\n",
       " 'El padrino',\n",
       " 'El caballero oscuro',\n",
       " 'El padrino: Parte II',\n",
       " 'El señor de los anillos: El retorno del rey',\n",
       " 'Pulp Fiction',\n",
       " 'La lista de Schindler',\n",
       " 'El bueno, el feo y el malo',\n",
       " '12 hombres sin piedad',\n",
       " 'Ayla: The Daughter of War',\n",
       " 'Origen',\n",
       " 'El club de la lucha',\n",
       " 'El señor de los anillos: La comunidad del anillo',\n",
       " 'Forrest Gump',\n",
       " 'El imperio contraataca']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clase para el año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearSpider:\n",
    "   \n",
    "    def __init__(self, url_pattern, pages_to_scrape=25, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    def scrape_url(self, url):\n",
    "                \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"Timeout error\")\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print(\"Redirect error\")\n",
    "        except requests.exceptions.SSLError:\n",
    "            print(\"SSL error\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error\")\n",
    "        \n",
    "        if response.status_code >= 400 and response.status_code < 500:\n",
    "            print('Request failed because the resource either does not exist or is forbidden')\n",
    "        elif response.status_code >= 300:\n",
    "            print('Request failed because the response server encountered an error')\n",
    "        \n",
    "        return self.content_parser(response.content)\n",
    "        \n",
    "    def kickstart(self):\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for i in range(0, self.pages_to_scrape):\n",
    "            \n",
    "            if self.sleep_interval > 0:\n",
    "                    time.sleep(self.sleep_interval)\n",
    "            \n",
    "            output.append(self.scrape_url(self.url_pattern % i))\n",
    "            exit = self.scrape_url(self.url_pattern % i)\n",
    "            if exit == 0:\n",
    "                print(\"No more pages to scrape\")\n",
    "                break\n",
    "        \n",
    "        return output\n",
    "\n",
    "URL_PATTERN = 'https://www.imdb.com/search/title?groups=top_1000&sort=user_rating,desc&count=100&start=%s01&ref_=adv_nxt' \n",
    "\n",
    "def year_parser(content):\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    text = [re.sub('\\D','', element.text) for element in soup.find_all('span', {\"class\":\"lister-item-year text-muted unbold\"}) if element.parent.name == 'h3']\n",
    "    \n",
    "    return text\n",
    "\n",
    "years_spider = YearSpider(URL_PATTERN, 10, content_parser=year_parser)\n",
    "years = [item for sublist in years_spider.kickstart() for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1994',\n",
       " '1972',\n",
       " '2008',\n",
       " '1974',\n",
       " '2003',\n",
       " '1994',\n",
       " '1993',\n",
       " '1966',\n",
       " '1957',\n",
       " '2017',\n",
       " '2010',\n",
       " '1999',\n",
       " '2001',\n",
       " '1994',\n",
       " '1980']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clase para el género."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GenreSpider:\n",
    "   \n",
    "    def __init__(self, url_pattern, pages_to_scrape=25, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    def scrape_url(self, url):\n",
    "                \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"Timeout error\")\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print(\"Redirect error\")\n",
    "        except requests.exceptions.SSLError:\n",
    "            print(\"SSL error\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error\")\n",
    "        \n",
    "        if response.status_code >= 400 and response.status_code < 500:\n",
    "            print('Request failed because the resource either does not exist or is forbidden')\n",
    "        elif response.status_code >= 300:\n",
    "            print('Request failed because the response server encountered an error')\n",
    "        \n",
    "        return self.content_parser(response.content)\n",
    "        \n",
    "    def kickstart(self):\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for i in range(0, self.pages_to_scrape):\n",
    "            \n",
    "            if self.sleep_interval > 0:\n",
    "                    time.sleep(self.sleep_interval)\n",
    "            \n",
    "            output.append(self.scrape_url(self.url_pattern % i))\n",
    "            exit = self.scrape_url(self.url_pattern % i)\n",
    "            if exit == 0:\n",
    "                print(\"No more pages to scrape\")\n",
    "                break\n",
    "        \n",
    "        return output\n",
    "\n",
    "URL_PATTERN = 'https://www.imdb.com/search/title?groups=top_1000&sort=user_rating,desc&count=100&start=%s01&ref_=adv_nxt' \n",
    "\n",
    "def genre_parser(content):\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    text = [element.text.strip().lstrip(\"\\n\") for element in soup.find_all('span', {\"class\":\"genre\"}) if element.parent.name == 'p']\n",
    "        \n",
    "    return text\n",
    "\n",
    "genres_spider = GenreSpider(URL_PATTERN, 10, content_parser=genre_parser)\n",
    "genres = [item for sublist in genres_spider.kickstart() for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drama',\n",
       " 'Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Biography, Drama, History',\n",
       " 'Western',\n",
       " 'Drama',\n",
       " 'Drama, History, War',\n",
       " 'Action, Adventure, Sci-Fi',\n",
       " 'Drama',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Fantasy']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clase para el score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '9.2',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '7.5',\n",
       " '7.5',\n",
       " '7.5',\n",
       " '7.5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ScoreSpider:\n",
    "   \n",
    "    def __init__(self, url_pattern, pages_to_scrape=25, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    def scrape_url(self, url):\n",
    "                \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"Timeout error\")\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print(\"Redirect error\")\n",
    "        except requests.exceptions.SSLError:\n",
    "            print(\"SSL error\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error\")\n",
    "        \n",
    "        if response.status_code >= 400 and response.status_code < 500:\n",
    "            print('Request failed because the resource either does not exist or is forbidden')\n",
    "        elif response.status_code >= 300:\n",
    "            print('Request failed because the response server encountered an error')\n",
    "        \n",
    "        return self.content_parser(response.content)\n",
    "        \n",
    "    def kickstart(self):\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for i in range(0, self.pages_to_scrape):\n",
    "            \n",
    "            if self.sleep_interval > 0:\n",
    "                    time.sleep(self.sleep_interval)\n",
    "            \n",
    "            output.append(self.scrape_url(self.url_pattern % i))\n",
    "            exit = self.scrape_url(self.url_pattern % i)\n",
    "            if exit == 0:\n",
    "                print(\"No more pages to scrape\")\n",
    "                break\n",
    "        \n",
    "        return output\n",
    "\n",
    "URL_PATTERN = 'https://www.imdb.com/search/title?groups=top_1000&sort=user_rating,desc&count=100&start=%s01&ref_=adv_nxt' \n",
    "\n",
    "def score_parser(content):\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    text = [element.text for element in soup.find_all('strong') if element.parent.name == 'div']\n",
    "    \n",
    "    return text\n",
    "\n",
    "scores_spider = ScoreSpider(URL_PATTERN, 10, content_parser=score_parser)\n",
    "scores = [item for sublist in scores_spider.kickstart() for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '9.2',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clase para ingresos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrossSpider:\n",
    "   \n",
    "    def __init__(self, url_pattern, pages_to_scrape=25, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    def scrape_url(self, url):\n",
    "                \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"Timeout error\")\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print(\"Redirect error\")\n",
    "        except requests.exceptions.SSLError:\n",
    "            print(\"SSL error\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Unknown error\")\n",
    "        \n",
    "        if response.status_code >= 400 and response.status_code < 500:\n",
    "            print('Request failed because the resource either does not exist or is forbidden')\n",
    "        elif response.status_code >= 300:\n",
    "            print('Request failed because the response server encountered an error')\n",
    "        \n",
    "        return self.content_parser(response.content)\n",
    "        \n",
    "    def kickstart(self):\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for i in range(0, self.pages_to_scrape):\n",
    "            \n",
    "            if self.sleep_interval > 0:\n",
    "                    time.sleep(self.sleep_interval)\n",
    "            \n",
    "            output.append(self.scrape_url(self.url_pattern % i))\n",
    "            exit = self.scrape_url(self.url_pattern % i)\n",
    "            if exit == 0:\n",
    "                print(\"No more pages to scrape\")\n",
    "                break\n",
    "        \n",
    "        return output\n",
    "\n",
    "URL_PATTERN = 'https://www.imdb.com/search/title?groups=top_1000&sort=user_rating,desc&count=100&start=%s01&ref_=adv_nxt' \n",
    "\n",
    "def gross_parser(content):\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    text = []\n",
    "    \n",
    "    mcount = 0\n",
    "    \n",
    "    for i, element in enumerate(soup.find_all('span', {\"name\":\"nv\"})):\n",
    "                \n",
    "        if element.parent.name == 'p' and element.text.endswith('M'):\n",
    "            text.append(float(element.text.lstrip(\"$\").rstrip('M')))\n",
    "            mcount = 0\n",
    "        else:\n",
    "            mcount += 1\n",
    "\n",
    "        if mcount >= 2 or (i==len(soup.find_all('span', {\"name\":\"nv\"}))-1 and mcount==1):\n",
    "            text.append(float(\"0\"))\n",
    "\n",
    "            \n",
    "    \n",
    "    return text\n",
    "\n",
    "gross_spider = GrossSpider(URL_PATTERN, 10, content_parser=gross_parser)\n",
    "gross = [item for sublist in gross_spider.kickstart() for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.34,\n",
       " 134.97,\n",
       " 534.86,\n",
       " 57.3,\n",
       " 377.85,\n",
       " 107.93,\n",
       " 96.07,\n",
       " 6.1,\n",
       " 4.36,\n",
       " 0.0,\n",
       " 292.58,\n",
       " 37.03,\n",
       " 315.54,\n",
       " 330.25,\n",
       " 290.48]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * En esta última clase estuvo uno de los principales desafíos técnicos, ya que en la página de origen, en las películas que no tenían un valor para los ingresos definido, no los tomaba y necesitaba los 1000 valores para luego poder mezclar las tablas, así que tuve que optar por un contador para que la función \"supiera\" cuándo había recogido 2 veces seguidas los números de votos, lo cual era señal de que esa película no tenía ingresos registrados, por lo que le asignaba 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se corrige gross añadiendo el valor que faltó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross = gross[:299] + [0] + gross[299:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se crea el dataframe con las listas obtenidas como columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Score</th>\n",
       "      <th>Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Collateral</td>\n",
       "      <td>2004</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>7.5</td>\n",
       "      <td>101.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Ice Age: La edad de hielo</td>\n",
       "      <td>2002</td>\n",
       "      <td>Animation, Adventure, Comedy</td>\n",
       "      <td>7.5</td>\n",
       "      <td>176.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Gangs of New York</td>\n",
       "      <td>2002</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>7.5</td>\n",
       "      <td>77.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Batman</td>\n",
       "      <td>1989</td>\n",
       "      <td>Action, Adventure</td>\n",
       "      <td>7.5</td>\n",
       "      <td>251.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>La mosca</td>\n",
       "      <td>1986</td>\n",
       "      <td>Drama, Horror, Sci-Fi</td>\n",
       "      <td>7.5</td>\n",
       "      <td>40.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title  Year                        Genres Score  \\\n",
       "995                 Collateral  2004        Crime, Drama, Thriller   7.5   \n",
       "996  Ice Age: La edad de hielo  2002  Animation, Adventure, Comedy   7.5   \n",
       "997          Gangs of New York  2002                  Crime, Drama   7.5   \n",
       "998                     Batman  1989             Action, Adventure   7.5   \n",
       "999                   La mosca  1986         Drama, Horror, Sci-Fi   7.5   \n",
       "\n",
       "      Gross  \n",
       "995  101.01  \n",
       "996  176.39  \n",
       "997   77.81  \n",
       "998  251.19  \n",
       "999   40.46  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ws = pd.DataFrame(\n",
    "    {'Title': titles,\n",
    "     'Year': years,\n",
    "     'Genres': genres,\n",
    "     'Score': scores,\n",
    "     'Gross': gross\n",
    "    })\n",
    "df_ws.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se corrigen los tipos en las columnas que son numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ws['Year'] = df_ws['Year'].astype('int')\n",
    "df_ws['Score'] = df_ws['Score'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se crea una tabla agrupando por año y con la media de score por cada año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2014</td>\n",
       "      <td>7.932258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2015</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2016</td>\n",
       "      <td>7.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2017</td>\n",
       "      <td>7.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2018</td>\n",
       "      <td>7.970588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year     Score\n",
       "92  2014  7.932258\n",
       "93  2015  7.900000\n",
       "94  2016  7.960000\n",
       "95  2017  7.920000\n",
       "96  2018  7.970588"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_year = df_ws.groupby('Year', as_index=False).agg({'Score':'mean'})\n",
    "score_year.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se crea una tabla agrupando por año y con la suma de ingresos por cada año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1920</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1921</td>\n",
       "      <td>5.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1922</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1924</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1925</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Gross\n",
       "0  1920   0.00\n",
       "1  1921   5.45\n",
       "2  1922   0.00\n",
       "3  1924   0.98\n",
       "4  1925   5.50"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_year = df_ws.groupby('Year', as_index=False).agg({'Gross':'sum'})\n",
    "gross_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se importan los datos de la API en formato json, y se hace una pequeña limpieza (se desechan las columnas no necesarias y se ajustan los nombres de las mismas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>US_GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1930</td>\n",
       "      <td>92.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1931</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1932</td>\n",
       "      <td>59.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1933</td>\n",
       "      <td>57.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1934</td>\n",
       "      <td>66.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  US_GDP\n",
       "0  1930    92.2\n",
       "1  1931    77.4\n",
       "2  1932    59.5\n",
       "3  1933    57.2\n",
       "4  1934    66.8"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api = pd.DataFrame(requests.get('https://pkgstore.datahub.io/core/gdp-us/year_json/data/37295f010ae077399baf63038818f935/year_json.json').json())\n",
    "df_api = df_api.drop(columns=['change-chained', 'change-current', 'level-chained'])\n",
    "df_api.columns = ['Year', 'US_GDP']\n",
    "df_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se unen las columnas de score y gross por año con la del PIB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Gross</th>\n",
       "      <th>US_GDP</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1930</td>\n",
       "      <td>3.27</td>\n",
       "      <td>92.2</td>\n",
       "      <td>8.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1931</td>\n",
       "      <td>12.05</td>\n",
       "      <td>77.4</td>\n",
       "      <td>8.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1932</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59.5</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1933</td>\n",
       "      <td>10.00</td>\n",
       "      <td>57.2</td>\n",
       "      <td>7.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1934</td>\n",
       "      <td>4.36</td>\n",
       "      <td>66.8</td>\n",
       "      <td>8.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Gross  US_GDP     Score\n",
       "0  1930   3.27    92.2  8.100000\n",
       "1  1931  12.05    77.4  8.075000\n",
       "2  1932   0.00    59.5  7.900000\n",
       "3  1933  10.00    57.2  7.866667\n",
       "4  1934   4.36    66.8  8.100000"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge1 = pd.merge(gross_year, df_api, on='Year')\n",
    "merge2 = pd.merge(merge1, score_year, on='Year')\n",
    "merge2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Se visualiza la correlación que hay entre el PIB y el ingreso anual, incluso entre el score y el año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Gross</th>\n",
       "      <th>US_GDP</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825436</td>\n",
       "      <td>0.889856</td>\n",
       "      <td>-0.435519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gross</th>\n",
       "      <td>0.825436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919684</td>\n",
       "      <td>-0.361776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_GDP</th>\n",
       "      <td>0.889856</td>\n",
       "      <td>0.919684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.383101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>-0.435519</td>\n",
       "      <td>-0.361776</td>\n",
       "      <td>-0.383101</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year     Gross    US_GDP     Score\n",
       "Year    1.000000  0.825436  0.889856 -0.435519\n",
       "Gross   0.825436  1.000000  0.919684 -0.361776\n",
       "US_GDP  0.889856  0.919684  1.000000 -0.383101\n",
       "Score  -0.435519 -0.361776 -0.383101  1.000000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "### - Se puede apreciar que existe una alta correlación entre el PIB y la suma de ingresos, incluso más alta que la que existe entre el PIB y el año, lo que podría llevar a pensar que la industria del cine y la economía de USA están relacionados.\n",
    "### - El Score no mostró ninguna relación considerable con ninguno de los otros valores, por lo que se podría haber ignorado. Sin embargo se mantuvieron para comprobar si existía alguna correlación con al menos el año, pero es incluso negativa.\n",
    "### - En cuanto a la parte técnica, a la hora de extraer la información de cada columna, se podía haber ahorrado algo de tiempo de espera de la recuperación de datos si se hubieran creado funciones separadas para extraer la información de la web, y luego trabajar aparte para manipularla, ya que con la forma en que se hizo cada vez que se corría la función había que hacer x cantidad de llamadas a la web. Pero se hizo de esta forma para mantener la estructura de la función empleada en otra ocasión la cual permite comprobación de errores y está muy bien estructurada y compactada en general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué más se podría hacer?\n",
    "### - Evaluar cómo se relacionan los scores con los géneros.\n",
    "### - Cómo han evolucionado los géneros (de las películas que han terminado siendo las más votadas) a través de los años, para evaluar las tendencias por época.\n",
    "### - Analizar la relación (si la hay) entre los géneros y los ingresos, para determinar los géneros más lucrativos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
